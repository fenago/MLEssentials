{"metadata":{"colab":{"name":"Chapter 6.ipynb","provenance":[]},"hide_input":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import basic libraries\nimport numpy as np \nimport pandas as pd \n\n# import visualization libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"colab":{},"colab_type":"code","id":"yB8LIZoeLgJZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import your data\ndf = pd.read_excel('https://github.com/fenago/MLEssentials/blob/f97bdc23282b62ffd81ef006b392e0cd660b4bfa/datasets/default_credit.xls?raw=true')\n","metadata":{"colab":{},"colab_type":"code","id":"16oH2bAoLgJh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GET TO KNOW YOUR DATA","metadata":{}},{"cell_type":"code","source":"df.head(5)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"colab_type":"code","id":"Pwr8jeojLgJm","outputId":"fa511a29-6bdf-4504-8b0f-241b35754865"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting Meta Data Information about the dataset\ndf.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":527},"colab_type":"code","id":"ovyQBhq5LgJs","outputId":"2f1e9f2e-5042-43ac-8138-b2a981a470e4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":824},"colab_type":"code","id":"uyLGpUJhLgJy","outputId":"29b3aaae-5e53-4e96-91a5-1cf73862c0ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for Null Values \ndf.isnull().sum()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":459},"colab_type":"code","id":"VZNPvj7JLgJ2","outputId":"4ef636e1-ac1a-40f2-cfa9-d9b7b2025926"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA PREPROCESSSING ","metadata":{"colab_type":"text","id":"i_MT1oI_LgJ5"}},{"cell_type":"markdown","source":"Before proceeding onto univariate analysis, let's look at the unique values in the columns. The motive behind looking at the unique values in a column is to identify the subcategory in each column. By knowing the subcategory in each column, we would be in a position to understand which subcategory has a higher count or vice versa. For example, let's take the EDUCATION column. We are interested in finding what the different subcategories in the EDUCATION column are and which subcategory has the higher count; that is, do our customers have their highest education as College or University?\n\nThis step acts as a precursor before we build a profile of our customers.\n\nLet's now find unique values in the SEX column.\n\nWe'll print the unique values in the SEX column and sort them in ascending order:","metadata":{}},{"cell_type":"code","source":"print('SEX ' + str(sorted(df['SEX'].unique())))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('EDUCATION ' + str(sorted(df['EDUCATION'].unique())))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('MARRIAGE ' + str(sorted(df['MARRIAGE'].unique())))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('PAY_0 ' + str(sorted(df['PAY_0'].unique())))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('default.payment.next.month ' + str(sorted(df['default payment next month'].unique())))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Do all of the above at once","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find unique values in your dataset.  Do this PER COLUMN. \n# This is univariate analysis.  You go column by column and get as much data as you can per column.\nprint('SEX ' + str(sorted(df['SEX'].unique())))\nprint('EDUCATION ' + str(sorted(df['EDUCATION'].unique())))\nprint('MARRIAGE ' + str(sorted(df['MARRIAGE'].unique())))\nprint('PAY_0 ' + str(sorted(df['PAY_0'].unique())))\nprint('default.payment.next.month ' + str(sorted(df['default payment next month'].unique())))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":102},"colab_type":"code","id":"dopsm0oQLgJ6","outputId":"9f3128d5-ab3e-4a5a-e1bb-50c6099eea47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Refer back to the data dictionary and clean the data\n# Data Dictionary: https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n# For instance, Education only has 4 values in the data dictionary (1-4) but it has 0-6 in the data.  So set 0,5, and 6 as 4 (other)\nfill = (df.EDUCATION == 0) | (df.EDUCATION == 5) | (df.EDUCATION == 6)\ndf.loc[fill, 'EDUCATION'] = 4\n\nprint('EDUCATION ' + str(sorted(df['EDUCATION'].unique())))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"xXwhX7FDLgJ_","outputId":"f4a39df9-ec0a-4c96-fe11-a4b3ff450715","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fill = (df.MARRIAGE == 0)\ndf.loc[fill, 'MARRIAGE'] = 2\n\nprint('MARRIAGE ' + str(sorted(df['MARRIAGE'].unique())))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","id":"WMJmNX0ELgKC","outputId":"1770c105-bc2d-4047-cda9-a60daa7e919e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename columns so they make sense to you\ndf = df.rename(columns={'default payment next month': 'DEFAULT', \n                        'PAY_0': 'PAY_1'})\ndf.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"colab_type":"code","id":"SZD3NM5nLgKG","outputId":"4879be09-723b-4b14-fe82-e1581e866844"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Univariate Analysis (Find as much data as you can using statistics in each column)","metadata":{}},{"cell_type":"markdown","source":"Univariate analysis is the simplest form of analysis where we analyze each feature (that is, each column of a DataFrame) and try to uncover the pattern or distribution of the data.\n\nIn univariate analysis, we will be analyzing the categorical columns (DEFAULT, SEX, EDUCATION, and MARRIAGE) to mine useful information about the data:\n\nLet's begin with each of the variables one by one:","metadata":{}},{"cell_type":"code","source":"sns.countplot(x=\"DEFAULT\", data=df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To analyze the distribution of the DEFAULT column, that is, the count of defaults versus non-defaults, use the following:","metadata":{}},{"cell_type":"code","source":"df['DEFAULT'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the preceding output, we see that around 6636 customers have defaulted out of 30000 people, which is around 22%.  Very important. \nThis is an insight that came from our analysis.  That is what we are trying to do.  Find insights!","metadata":{}},{"cell_type":"code","source":"sns.countplot(x=\"SEX\", data=df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['SEX'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=\"EDUCATION\", data=df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['EDUCATION'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=\"MARRIAGE\", data=df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['MARRIAGE'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How many insights could you pull from a Univariate Analysis?  This is a powerful technique?  You could keep going but this is the idea.","metadata":{}},{"cell_type":"code","source":"# Pull the descriptive statistics and FIND INSIGHTS!\n# What do the averages tell you?  What insights can you find?\ndf.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bivariate Analysis (Find as much info as you can when you compare 2 columns of data)","metadata":{"colab":{},"colab_type":"code","id":"DypZT7YCLgK8"}},{"cell_type":"markdown","source":"Bivariate analysis is performed between two variables to look at their relationship.\n\nIn this section, you will consider the relationship between the DEFAULT column and other columns in the DataFrame with the help of the crosstab function and visualization techniques.","metadata":{}},{"cell_type":"markdown","source":"The SEX column versus the DEFAULT column:\nIn this section, you will look at the relationship between the SEX and DEFAULT columns by plotting a count plot with the hue as DEFAULT to compare the number of male customers who have defaulted with the number of female customers who have defaulted:","metadata":{}},{"cell_type":"code","source":"sns.set(rc={'figure.figsize':(15,10)})\nedu = sns.countplot(x='SEX', hue='DEFAULT', data=df)\nedu.set_xticklabels(['Male','Female'])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the preceding graph, you can see that females have defaulted more than males. But this graph doesn't show us the complete picture. To determine what percentage of each sex has defaulted, we will perform cross-tabulation.\n\nCross-tabulation is a technique used to show the relationship between two or more categorical values. For example, in this scenario, we would like to find the relationship between DEFAULT and SEX. A crosstab table will show you the count of customers for each of the following combinations:","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df.SEX,df.DEFAULT,normalize='index',margins=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this table, we can see that SEX subcategory 1 has 9015 people who have not defaulted ( DEFAULT :0) and 2873 people who have defaulted, while subcategory 2 in SEX has 14349 people who have not defaulted and 3763 people who have defaulted.\n\nWe can also find the percentage distribution for each pair by passing in the normalize='index' parameter, as follows:\n\npd.crosstab(df.SEX,df.DEFAULT,normalize='index',margins=True)","metadata":{}},{"cell_type":"code","source":"sns.set(rc={'figure.figsize':(15,10)})\nedu = sns.countplot(x='EDUCATION', hue='DEFAULT', data=df)\nedu.set_xticklabels(['Graduate School','University','High School','Other'])\nplt.show()\n","metadata":{"colab":{},"colab_type":"code","id":"vfjMQpIyLgK-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df.EDUCATION,df.DEFAULT,normalize='index')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(rc={'figure.figsize':(12,10)})\nmarriage = sns.countplot(x=\"MARRIAGE\", hue='DEFAULT', data=df )\nmarriage.set_xticklabels(['Married','Single','Other'])\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df.MARRIAGE,df.DEFAULT,normalize='index',margins=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df.AGE,df.DEFAULT)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df.AGE,df.DEFAULT,normalize='index',margins=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PAY_1 versus DEFAULT\nIn this section, we will be looking at the relationship between the DEFAULT and PAY_1 columns (the repayment status in the month of September 2005).\n\nThe measurement scale for the repayment status is as follows:\n (-1)-paid on time, 1 means 1 month delay, 2 means 2 month delay, etc.\n \n We can use the crosstab function to visualize the relationship between DEFAULT and PAY_1. This gives the percentage of defaults for each subcategory:","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df.PAY_1,df.DEFAULT,margins=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at Default versus Limit Balance","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x=\"DEFAULT\", y=\"LIMIT_BAL\", jitter=True, data=df);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at Age versus Default","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df.AGE,df.DEFAULT)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"To determine which age group has the highest default percentage, perform cross-tabulation with normalize= 'Index':\npd.crosstab(df.AGE,df.DEFAULT,normalize='index',margins=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df.AGE,df.DEFAULT,normalize='index',margins=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the preceding output, we can see that even though the ages 27 and 29 had higher counts of defaults, the percentage-wise default count paints a different picture. Those customers of the age of 22 had a higher percentage of defaulters than non-defaulters.","metadata":{}},{"cell_type":"markdown","source":"## Correlation","metadata":{}},{"cell_type":"markdown","source":"In this section, we will cover correlation â€“ what does correlation mean, and how do we check the correlation between the DEFAULT column and other columns in our dataset?\n\nCorrelation measures the degree of dependency between any two variables. Say, for example, we have two variables, A and B. If the value of B increases when the value of A is increased, we say the variables are positively correlated. On the other hand, if the value of B decreases when we increase the value of A, we say the variables are negatively correlated. There could also be a situation where an increase in the value of A doesn't affect the value of B, for which we say the variables are uncorrelated.\n\nThe value of a correlation coefficient can vary between -1 to 1, with 1 being a strong positive correlation and -1 a strong negative correlation.\n\nBy studying the correlation between the DEFAULT column and other columns with the help of a heatmap, we can figure out which column/variable has a high impact on the DEFAULT column.\n\nIn this section, we will be using Spearman's rank correlation to check the correlation between two variables. The main reason for using Spearman's rank correlation is that it does not assume that the data is normally distributed, and it can be used between ordinal variables.","metadata":{}},{"cell_type":"code","source":"sns.set(rc={'figure.figsize':(30,10)})\nsns.set_context(\"talk\", font_scale=0.7)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df.iloc[:,1:].corr(method='spearman'), cmap='rainbow_r', annot=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(\"DEFAULT\", axis=1).apply(lambda x: x.corr(df.DEFAULT,method='spearman'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##  Now you find a dataset and do a Univariate, Bivariate, and Correlation Analysis","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary\n### Building a Profile of a High-Risk Customer\nBased on the analysis performed in the previous sections, we can now build a profile of the customer who is most likely to default. With this predicted customer profile, credit card companies can take preventive steps (such as reducing credit limits or increasing the rate of interest) and can demand additional collateral from customers who are deemed to be high risk.\n\nThe customer who satisfies the majority of the following conditions can be classified as a high-risk customer. A high-risk customer is one who has a higher probability of default:\n\nA male customer is more likely to default than a female customer.\nPeople with a relationship status of other are more likely to default than married or single people.\nA customer whose highest educational qualification is a high-school diploma is more likely to default than a customer who has gone to graduate school or university.\nA customer who has delayed payment for 2 consecutive months has a higher probability of default.\nA customer who is 22 years of age has a higher probability of defaulting on payments than any other age group.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}